/home/liuy6/anaconda3/envs/yy/bin/python3 /home/liuy6/.pycharm_helpers/pydev/pydevd.py --multiprocess --qt-support=auto --client localhost --port 34795 --file /home/liuy6/host/mmdetection/tools/loss_landscape/test_loss.py ../../configs/pascal_voc/faster-rcnn_loss_landscape.py ../../checkpoints/faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth 
Connected to pydev debugger (build 223.8214.51)
pydev debugger: warning: trying to add breakpoint to file that does not exist: /home/liuy6/host/mmdetection/tools/mmengine-main/mmengine/optim/optimizer/optimizer_wrapper.py (will have no effect)
09/23 09:25:32 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 1164303346
    GPU 0,1: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.8, V11.8.89
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 1.10.1
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

    TorchVision: 0.11.2
    OpenCV: 4.7.0
    MMEngine: 0.7.3

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: None
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

09/23 09:25:33 - mmengine - INFO - Config:
model = dict(
    type='LossFasterRCNN',
    data_preprocessor=dict(
        type='DetDataPreprocessor',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        bgr_to_rgb=True,
        pad_size_divisor=32),
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=20,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
dataset_type = 'VOCDataset'
data_root = '/home/liuy6/host/causal_rodc/data/'
backend_args = None
test_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(type='Resize', scale=(1000, 600), keep_ratio=True),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='PackDetInputs',
        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                   'scale_factor'))
]
val_dataloader = dict(
    batch_size=1,
    num_workers=2,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='VOCDataset',
        data_root='/home/liuy6/host/causal_rodc/data/',
        ann_file='VOC2007/ImageSets/Main/train.txt',
        data_prefix=dict(sub_data_root='VOC2007/'),
        filter_cfg=dict(filter_empty_gt=True, min_size=32, bbox_min_size=32),
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='Resize', scale=(1000, 600), keep_ratio=True),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ],
        backend_args=None))
test_dataloader = dict(
    batch_size=1,
    num_workers=2,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='VOCDataset',
        data_root='/home/liuy6/host/causal_rodc/data/',
        ann_file='VOC2007/ImageSets/Main/train.txt',
        data_prefix=dict(sub_data_root='VOC2007/'),
        filter_cfg=dict(filter_empty_gt=True, min_size=32, bbox_min_size=32),
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='Resize', scale=(1000, 600), keep_ratio=True),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ],
        backend_args=None))
train_dataloader = dict(
    batch_size=1,
    num_workers=2,
    persistent_workers=True,
    drop_last=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='VOCDataset',
        data_root='/home/liuy6/host/causal_rodc/data/',
        ann_file='VOC2007/ImageSets/Main/train.txt',
        data_prefix=dict(sub_data_root='VOC2007/'),
        filter_cfg=dict(filter_empty_gt=True, min_size=32, bbox_min_size=32),
        pipeline=[
            dict(type='LoadImageFromFile', backend_args=None),
            dict(type='Resize', scale=(1000, 600), keep_ratio=True),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='PackDetInputs',
                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',
                           'scale_factor'))
        ],
        backend_args=None))
val_evaluator = dict(type='CollectLossMetric')
test_evaluator = dict(type='CollectLossMetric')
default_scope = 'mmdet'
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=1),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(type='CheckpointHook', interval=1),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='DetVisualizationHook'))
env_cfg = dict(
    cudnn_benchmark=False,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [
    dict(type='TensorboardVisBackend'),
    dict(type='LocalVisBackend')
]
visualizer = dict(
    type='DetLocalVisualizer',
    vis_backends=[
        dict(type='TensorboardVisBackend'),
        dict(type='LocalVisBackend')
    ],
    name='visualizer')
log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)
log_level = 'INFO'
load_from = '../../checkpoints/faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth'
resume = False
max_epochs = 4
train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=4, val_interval=1)
val_cfg = dict(type='ValLossLoop')
test_cfg = dict(type='TestLossLoop')
param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=4,
        by_epoch=True,
        milestones=[3],
        gamma=0.1)
]
custom_hooks = [dict(type='PlotLossHook')]
optim_wrapper = dict(
    type='LossOptimWrapper',
    optimizer=dict(
        type='LandScape',
        x_min=-0.1,
        x_max=0.1,
        x_num=11,
        y_min=-0.1,
        y_max=0.1,
        y_num=11))
auto_scale_lr = dict(enable=False, base_batch_size=16)
launcher = 'none'
work_dir = './work_dirs/faster-rcnn_loss_landscape'

09/23 09:25:40 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
09/23 09:25:40 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) PlotLossHook                       
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(NORMAL      ) PlotLossHook                       
 -------------------- 
after_train:
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
09/23 09:25:45 - mmengine - WARNING - The prefix is not set in metric class CollectLossMetric.
Loads checkpoint by local backend from path: ../../checkpoints/faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth
The model and loaded state dict do not match exactly

size mismatch for neck.lateral_convs.0.conv.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([255, 256, 1, 1]).
size mismatch for neck.lateral_convs.0.conv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([255]).
size mismatch for neck.lateral_convs.1.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([255, 512, 1, 1]).
size mismatch for neck.lateral_convs.1.conv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([255]).
size mismatch for neck.lateral_convs.2.conv.weight: copying a param with shape torch.Size([256, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([255, 1024, 1, 1]).
size mismatch for neck.lateral_convs.2.conv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([255]).
size mismatch for neck.lateral_convs.3.conv.weight: copying a param with shape torch.Size([256, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([255, 2048, 1, 1]).
size mismatch for neck.lateral_convs.3.conv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([255]).
missing keys in source state_dict: neck.ln_convs.0.conv.weight, neck.ln_convs.0.conv.bias, neck.ln_convs.1.conv.weight, neck.ln_convs.1.conv.bias, neck.ln_convs.2.conv.weight, neck.ln_convs.2.conv.bias, neck.ln_convs.3.conv.weight, neck.ln_convs.3.conv.bias

09/23 09:25:48 - mmengine - INFO - Load checkpoint from ../../checkpoints/faster_rcnn_r50_fpn_1x_voc0712_20220320_192712-54bef0f3.pth
pydev debugger: warning: trying to add breakpoint to file that does not exist: /home/liuy6/host/mmdetection/tools/mmengine-main/mmengine/optim/optimizer/optimizer_wrapper.py (will have no effect)
pydev debugger: warning: trying to add breakpoint to file that does not exist: /home/liuy6/host/mmdetection/tools/mmengine-main/mmengine/optim/optimizer/optimizer_wrapper.py (will have no effect)
pydev debugger: warning: trying to add breakpoint to file that does not exist: /home/liuy6/host/mmdetection/tools/mmengine-main/mmengine/optim/optimizer/optimizer_wrapper.py (will have no effect)
pydev debugger: warning: trying to add breakpoint to file that does not exist: /home/liuy6/host/mmdetection/tools/mmengine-main/mmengine/optim/optimizer/optimizer_wrapper.py (will have no effect)
pydev debugger: warning: trying to add breakpoint to file that does not exist: /home/liuy6/host/mmdetection/tools/mmengine-main/mmengine/optim/optimizer/optimizer_wrapper.py (will have no effect)
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   1/2501]    eta: 1:38:25  time: 2.3620  data_time: 1.5121  memory: 906  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   2/2501]    eta: 0:50:47  time: 1.2197  data_time: 0.7617  memory: 1525  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   3/2501]    eta: 0:34:49  time: 0.8366  data_time: 0.5085  memory: 2250  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   4/2501]    eta: 0:27:02  time: 0.6496  data_time: 0.3830  memory: 2962  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   5/2501]    eta: 0:22:25  time: 0.5389  data_time: 0.3079  memory: 3701  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   6/2501]    eta: 0:19:20  time: 0.4652  data_time: 0.2580  memory: 4347  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   7/2501]    eta: 0:17:10  time: 0.4132  data_time: 0.2221  memory: 5009  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   8/2501]    eta: 0:15:28  time: 0.3724  data_time: 0.1953  memory: 5626  
09/23 09:25:51 - mmengine - INFO - Epoch(test) [   9/2501]    eta: 0:14:09  time: 0.3408  data_time: 0.1744  memory: 6351  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  10/2501]    eta: 0:13:07  time: 0.3163  data_time: 0.1576  memory: 7035  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  11/2501]    eta: 0:12:15  time: 0.2956  data_time: 0.1439  memory: 7752  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  12/2501]    eta: 0:11:33  time: 0.2787  data_time: 0.1324  memory: 8469  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  13/2501]    eta: 0:10:58  time: 0.2647  data_time: 0.1228  memory: 9085  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  14/2501]    eta: 0:10:27  time: 0.2523  data_time: 0.1145  memory: 9801  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  15/2501]    eta: 0:10:01  time: 0.2418  data_time: 0.1073  memory: 10289  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  16/2501]    eta: 0:09:37  time: 0.2325  data_time: 0.1011  memory: 10908  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  17/2501]    eta: 0:09:16  time: 0.2241  data_time: 0.0955  memory: 11525  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  18/2501]    eta: 0:08:58  time: 0.2168  data_time: 0.0906  memory: 12241  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  19/2501]    eta: 0:08:43  time: 0.2109  data_time: 0.0862  memory: 12817  
09/23 09:25:52 - mmengine - INFO - Epoch(test) [  20/2501]    eta: 0:08:26  time: 0.2043  data_time: 0.0825  memory: 13533  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  21/2501]    eta: 0:08:14  time: 0.1992  data_time: 0.0800  memory: 14181  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  22/2501]    eta: 0:08:01  time: 0.1943  data_time: 0.0775  memory: 14799  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  23/2501]    eta: 0:07:49  time: 0.1896  data_time: 0.0744  memory: 15516  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  24/2501]    eta: 0:07:37  time: 0.1847  data_time: 0.0716  memory: 16238  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  25/2501]    eta: 0:07:26  time: 0.1805  data_time: 0.0690  memory: 16722  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  26/2501]    eta: 0:07:17  time: 0.1768  data_time: 0.0670  memory: 17447  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  27/2501]    eta: 0:07:08  time: 0.1733  data_time: 0.0648  memory: 17966  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  28/2501]    eta: 0:07:00  time: 0.1699  data_time: 0.0630  memory: 18616  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  29/2501]    eta: 0:06:52  time: 0.1668  data_time: 0.0613  memory: 19331  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  30/2501]    eta: 0:06:46  time: 0.1646  data_time: 0.0603  memory: 19926  
09/23 09:25:53 - mmengine - INFO - Epoch(test) [  31/2501]    eta: 0:06:41  time: 0.1624  data_time: 0.0594  memory: 20504  
09/23 09:25:54 - mmengine - INFO - Epoch(test) [  32/2501]    eta: 0:06:34  time: 0.1599  data_time: 0.0581  memory: 21223  

Process finished with exit code 143
